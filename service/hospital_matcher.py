"""
Processeur principal pour le matching des √©tablissements de sant√©
"""

import pandas as pd
import time
import sys
import os

# Ajouter le r√©pertoire parent au path pour les imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from fuzzywuzzy import fuzz
from config import *
from establishment_utils import (
    get_establishment_name_and_type, 
    clean_name, 
    detect_establishment_type,
    get_best_candidate_name
)
from ai_service import ai_compare_hospital_names_batch
from geo_utils import normalize_city_name, normalize_department_name


class HospitalMatcher:
    """
    Classe principale pour le matching des √©tablissements de sant√©
    """
    
    def __init__(self, reset_history=False, differentiate_types=False, forced_type=None):
        self.total_ai_requests = 0
        self.processed_hospitals = 0
        self.df_lp = None
        self.df_sc = None
        self.last_save_index = 0  # Pour tracking des sauvegardes
        self.reset_history = reset_history
        self.differentiate_types = differentiate_types
        self.forced_type = forced_type  # None, "hopital", "clinique"
    
    def load_data(self):
        """
        Charge les donn√©es depuis les fichiers Excel et v√©rifie le travail d√©j√† fait
        """
        print("üìÇ Chargement des donn√©es...")
        try:
            self.df_lp = pd.read_excel(PATH_TABLE_A)
            self.df_sc = pd.read_excel(PATH_TABLE_B)
            print(f"‚úÖ Donn√©es sources charg√©es: {len(self.df_lp)} √©tablissements √† traiter, {len(self.df_sc)} r√©f√©rences")
            
            # V√©rifier si le fichier de r√©sultats existe d√©j√†
            self._check_existing_results()
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des donn√©es: {e}")
            raise
    
    def _check_existing_results(self):
        """
        V√©rifie s'il existe d√©j√† des r√©sultats et les charge si possible
        """
        # Si l'utilisateur veut reset l'historique, on efface le fichier existant
        if self.reset_history:
            if os.path.exists(OUTPUT_PATH):
                try:
                    os.remove(OUTPUT_PATH)
                    print("üîÑ Historique effac√© - nouveau traitement complet")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur lors de l'effacement de l'historique: {e}")
            
            # IMPORTANT: Toujours initialiser √† None quand on reset
            print("üÜï Nouveau traitement complet demand√©")
            self.df_lp[COLA_FINESS] = None
            if COLA_MATCH_NAME not in self.df_lp.columns:
                self.df_lp[COLA_MATCH_NAME] = None
            else:
                self.df_lp[COLA_MATCH_NAME] = None
            if COLA_MATCH_CONFIDENCE not in self.df_lp.columns:
                self.df_lp[COLA_MATCH_CONFIDENCE] = None
            else:
                self.df_lp[COLA_MATCH_CONFIDENCE] = None
            return
        
        # Seulement si on ne reset PAS l'historique
        if os.path.exists(OUTPUT_PATH):
            try:
                existing_df = pd.read_excel(OUTPUT_PATH)
                print(f"üìã Fichier de r√©sultats existant trouv√©: {OUTPUT_PATH}")
                
                # V√©rifier si les colonnes correspondent
                if (len(existing_df) == len(self.df_lp) and 
                    COLA_FINESS in existing_df.columns):
                    
                    # Copier les r√©sultats existants
                    self.df_lp[COLA_FINESS] = existing_df[COLA_FINESS]
                    
                    # Copier les nouvelles colonnes si elles existent
                    if COLA_MATCH_NAME in existing_df.columns:
                        self.df_lp[COLA_MATCH_NAME] = existing_df[COLA_MATCH_NAME]
                    else:
                        self.df_lp[COLA_MATCH_NAME] = None
                        
                    if COLA_MATCH_CONFIDENCE in existing_df.columns:
                        self.df_lp[COLA_MATCH_CONFIDENCE] = existing_df[COLA_MATCH_CONFIDENCE]
                    else:
                        self.df_lp[COLA_MATCH_CONFIDENCE] = None
                    
                    # Compter les h√¥pitaux d√©j√† trait√©s
                    already_processed = self.df_lp[COLA_FINESS].notna().sum()
                    print(f"üîÑ Reprise du traitement: {already_processed} h√¥pitaux d√©j√† trait√©s")
                    print(f"üìù Reste √† traiter: {len(self.df_lp) - already_processed} h√¥pitaux")
                else:
                    print("‚ö†Ô∏è  Structure diff√©rente d√©tect√©e, nouveau traitement complet")
                    self.df_lp[COLA_FINESS] = None
                    self.df_lp[COLA_MATCH_NAME] = None
                    self.df_lp[COLA_MATCH_CONFIDENCE] = None
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lors de la lecture du fichier existant: {e}")
                print("üîÑ D√©marrage d'un nouveau traitement...")
                self.df_lp[COLA_FINESS] = None
                self.df_lp[COLA_MATCH_NAME] = None
                self.df_lp[COLA_MATCH_CONFIDENCE] = None
        else:
            print("üÜï Nouveau traitement - aucun fichier de r√©sultats existant")
            self.df_lp[COLA_FINESS] = None
            self.df_lp[COLA_MATCH_NAME] = None
            self.df_lp[COLA_MATCH_CONFIDENCE] = None
    
    def process_all_hospitals(self):
        """
        Traite tous les h√¥pitaux du fichier avec optimisations et reprise automatique
        """
        if self.df_lp is None or self.df_sc is None:
            raise ValueError("Les donn√©es doivent √™tre charg√©es avant le traitement")
        
        # V√©rification critique : s'assurer que la colonne FINESS est bien vide si reset
        if self.reset_history:
            self.df_lp[COLA_FINESS] = None
            print("üîÑ Reset confirm√© : colonne FINESS r√©initialis√©e")
        
        # Initialiser les nouvelles colonnes si elles n'existent pas
        if COLA_MATCH_NAME not in self.df_lp.columns:
            self.df_lp[COLA_MATCH_NAME] = None
        if COLA_MATCH_CONFIDENCE not in self.df_lp.columns:
            self.df_lp[COLA_MATCH_CONFIDENCE] = None
        # Ajouter une colonne pour tracer la source du nom match√©
        if "Source_Nom_Match" not in self.df_lp.columns:
            self.df_lp["Source_Nom_Match"] = None

        # Compter les h√¥pitaux d√©j√† trait√©s
        already_processed = self.df_lp[COLA_FINESS].notna().sum()
        total_hospitals = len(self.df_lp)
        remaining = total_hospitals - already_processed
        
        print(f"\nüè• D√©marrage du traitement:")
        print(f"üìä Total: {total_hospitals} √©tablissements")
        print(f"‚úÖ D√©j√† trait√©s: {already_processed}")
        print(f"üìù Reste √† traiter: {remaining}")
        print(f"üíæ Sauvegarde automatique tous les {SAVE_INTERVAL} √©tablissements")
        
        # Ne traiter que les h√¥pitaux non encore trait√©s
        for idx, row in self.df_lp.iterrows():
            # V√©rifier si cet h√¥pital a d√©j√† √©t√© trait√©
            if pd.notna(self.df_lp.at[idx, COLA_FINESS]):
                continue  # Passer au suivant
            
            self._process_single_hospital(idx, row)
            
            # Sauvegarde r√©guli√®re tous les SAVE_INTERVAL
            if (self.processed_hospitals % SAVE_INTERVAL == 0 and 
                self.processed_hospitals > self.last_save_index):
                self._save_intermediate_results(self.processed_hospitals)
                self.last_save_index = self.processed_hospitals
        
        self._print_final_statistics()
    
    def _process_single_hospital(self, idx, row):
        """
        Traite un seul h√¥pital (seulement s'il n'a pas d√©j√† √©t√© trait√©)
        """
        self.processed_hospitals += 1
        
        # Calculer le nombre total d'h√¥pitaux restants √† traiter
        total_remaining = self.df_lp[COLA_FINESS].isna().sum()
        current_remaining = total_remaining - self.processed_hospitals + 1
        
        print(f"\n=== Traitement {self.processed_hospitals} - Index: {idx} ===")
        print(f"üìà Progression: {current_remaining} h√¥pitaux restants")
        
        # Obtenir le nom et le type d'√©tablissement
        establishment_name, establishment_type = get_establishment_name_and_type(row)
        
        # Appliquer les param√®tres de gestion des types
        if not self.differentiate_types:
            establishment_type = "unknown"  # Ignorer le type
        elif self.forced_type:
            establishment_type = self.forced_type  # Forcer un type sp√©cifique
        
        if not establishment_name:
            print(f"‚ùå Aucun nom d'√©tablissement trouv√© pour la ligne {idx}")
            self.df_lp.at[idx, COLA_FINESS] = None
            return
        
        type_info = f" (Type: {establishment_type.upper()})" if self.differentiate_types else " (Type ignor√©)"
        print(f"üîç Recherche pour: {establishment_name}{type_info}")
        
        # Affichage s√©curis√© des informations g√©ographiques
        ville_info = row[COLA_VILLE] if COLA_VILLE and COLA_VILLE in row.index else "N/A"
        dept_info = row[COLA_DEPARTEMENT] if COLA_DEPARTEMENT and COLA_DEPARTEMENT in row.index else "N/A"
        print(f"üìç Ville: {ville_info} | D√©partement: {dept_info}")
        
        # Filtrer les candidats par ville
        candidates = self._find_candidates_in_city(row, establishment_name, establishment_type)
        
        if not candidates:
            print(f"‚ùå Aucun √©tablissement trouv√© dans {ville_info} ({dept_info})")
            self.df_lp.at[idx, COLA_FINESS] = None
            return
        
        # Essayer le matching
        result = self._match_establishment(establishment_name, establishment_type, candidates)
        
        # G√©rer le retour avec 4 valeurs
        if len(result) == 4:
            selected_finess, matched_name, confidence_score, source_column = result
        else:
            # Compatibilit√© avec l'ancien format (3 valeurs)
            selected_finess, matched_name, confidence_score = result
            source_column = "COLB_NOM_SC"  # Valeur par d√©faut
        
        if selected_finess:
            self.df_lp.at[idx, COLA_FINESS] = selected_finess
            self.df_lp.at[idx, COLA_MATCH_NAME] = matched_name
            self.df_lp.at[idx, COLA_MATCH_CONFIDENCE] = confidence_score
            self.df_lp.at[idx, "Source_Nom_Match"] = source_column
            print(f"‚úÖ FINESS assign√©: {selected_finess} (Confiance: {confidence_score}%)")
            print(f"   Nom match√©: {matched_name} (Source: {source_column})")
        else:
            self.df_lp.at[idx, COLA_FINESS] = None
            self.df_lp.at[idx, COLA_MATCH_NAME] = None
            self.df_lp.at[idx, COLA_MATCH_CONFIDENCE] = 0
            self.df_lp.at[idx, "Source_Nom_Match"] = None
            print(f"‚ùå Aucun match trouv√©")
        
        print(f"üìä Requ√™tes IA utilis√©es: {self.total_ai_requests}")
        
        # Petite pause pour √©viter la surcharge API
        if self.total_ai_requests > 0 and self.total_ai_requests % 10 == 0:
            print("‚è≥ Pause de 5 secondes pour √©viter la surcharge API...")
            time.sleep(5)
    
    def _find_candidates_in_city(self, row, establishment_name, establishment_type):
        """
        Trouve tous les candidats dans la m√™me ville/d√©partement avec normalisation
        """
        # Utiliser la strat√©gie g√©ographique configur√©e
        from config import get_geo_comparison_strategy
        geo_strategy = get_geo_comparison_strategy()
        
        # V√©rifier que les colonnes existent avant de les utiliser
        search_city = None
        search_dept = None
        
        if geo_strategy["use_city"] and COLA_VILLE and COLA_VILLE in row.index:
            search_city = normalize_city_name(row[COLA_VILLE])
        
        if geo_strategy["use_department"] and COLA_DEPARTEMENT and COLA_DEPARTEMENT in row.index:
            search_dept = normalize_department_name(row[COLA_DEPARTEMENT])
        
        print(f"üìç Recherche normalis√©e: {search_city} ({search_dept})")
        print(f"üó∫Ô∏è Strat√©gie g√©o: {geo_strategy['type']} ({'ville' if geo_strategy['use_city'] else ''}{' + ' if geo_strategy['both'] else ''}{'d√©partement' if geo_strategy['use_department'] else ''})")
        
        if not search_city and not search_dept:
            print("‚ùå Impossible de normaliser la ville/d√©partement ou colonnes manquantes")
            return []
        
        # Filtrer avec normalisation g√©ographique optimis√©e
        candidates_indices = []
        
        for idx, candidate_row in self.df_sc.iterrows():
            candidate_city = None
            candidate_dept = None
            
            # V√©rifier que les colonnes existent avant de les utiliser
            if geo_strategy["use_city"] and COLB_VILLE and COLB_VILLE in candidate_row.index:
                candidate_city = normalize_city_name(candidate_row[COLB_VILLE])
            
            if geo_strategy["use_department"] and COLB_DEPARTEMENT and COLB_DEPARTEMENT in candidate_row.index:
                candidate_dept = normalize_department_name(candidate_row[COLB_DEPARTEMENT])
            
            # Logique de correspondance selon la strat√©gie
            match_found = False
            
            if geo_strategy["city_only"]:
                # Ville uniquement
                match_found = (search_city and candidate_city and 
                             (search_city == candidate_city or 
                              search_city in candidate_city or 
                              candidate_city in search_city))
            
            elif geo_strategy["department_only"]:
                # D√©partement uniquement
                match_found = (search_dept and candidate_dept and search_dept == candidate_dept)
            
            elif geo_strategy["both"]:
                # Ville ET d√©partement
                city_match = (search_city and candidate_city and 
                             (search_city == candidate_city or 
                              search_city in candidate_city or 
                              candidate_city in search_city))
                dept_match = (search_dept and candidate_dept and search_dept == candidate_dept)
                
                # Accepter si ville ET d√©partement correspondent, ou si seulement ville correspond (si pas de dept)
                if search_dept and candidate_dept:
                    match_found = city_match and dept_match
                else:
                    # Si pas de d√©partement disponible, utiliser seulement la ville
                    match_found = city_match
            
            if match_found:
                candidates_indices.append(idx)
        
        if not candidates_indices:
            print(f"‚ùå Aucun candidat trouv√© avec les crit√®res g√©ographiques")
            return []
        
        df_sc_filtered = self.df_sc.loc[candidates_indices]
        print(f"üè¢ {len(df_sc_filtered)} √©tablissements trouv√©s")
        
        # Pr√©parer les candidats avec filtrage par type
        all_candidates = []
        same_type_candidates = []
        
        for idx, row_sc in df_sc_filtered.iterrows():
            # Prioriser COLB_NOM_SC (colonne principale de matching) 
            # plut√¥t que de choisir automatiquement le nom le plus long
            best_name = get_best_candidate_name(
                row_sc, 
                [COLB_NOM_SC, COLB_NOM, COLB_NOM_2], 
                prioritize_first=True  # Prioriser la premi√®re colonne (celle du matching)
            )
            candidate_info = (best_name, row_sc[COLB_FIN_SCS])
            all_candidates.append(candidate_info)
            
            # Garder s√©par√©ment les candidats du m√™me type SEULEMENT si on diff√©rencie les types
            if self.differentiate_types and establishment_type != "unknown":
                candidate_type = detect_establishment_type(best_name)
                if candidate_type == establishment_type:
                    same_type_candidates.append(candidate_info)
        
        # Choisir les candidats √† utiliser
        if self.differentiate_types and same_type_candidates:
            candidates = same_type_candidates
            print(f"üéØ Trouv√© {len(same_type_candidates)} candidats du m√™me type ({establishment_type})")
        else:
            candidates = all_candidates
            if self.differentiate_types:
                print(f"‚ö†Ô∏è  Aucun candidat du type {establishment_type}, utilisation de tous les candidats ({len(all_candidates)})")
            else:
                print(f"üéØ Tous types confondus: {len(all_candidates)} candidats")
        
        return candidates
    
    def _match_establishment(self, establishment_name, establishment_type, candidates):
        """
        Effectue le matching d'un √©tablissement avec les candidats (optimis√© IA)
        
        Returns:
            tuple: (finess, nom_match√©, score_confiance, source_colonne) ou (None, None, 0, None) si pas de match
        """
        establishment_name_clean = clean_name(establishment_name)
        
        # Si un seul candidat, pas besoin de fuzzy ou IA
        if len(candidates) == 1:
            print(f"üéØ Un seul candidat disponible: {candidates[0][0]}")
            return candidates[0][1], candidates[0][0], 95, "COLB_NOM_SC"  # Supposer que c'est la colonne principale
        
        # Essayer d'abord le matching fuzzy
        best_match_idx, best_score = self._fuzzy_match(establishment_name_clean, candidates)
        
        if best_score > FUZZY_THRESHOLD:
            print(f"üéØ Match fuzzy trouv√© (score: {best_score})")
            print(f"   {establishment_name_clean} -> {candidates[best_match_idx][0]}")
            return candidates[best_match_idx][1], candidates[best_match_idx][0], best_score, "COLB_NOM_SC"
        else:
            # Utiliser l'IA pour choisir PARMI TOUS les candidats en une seule requ√™te
            print(f"ü§ñ Score fuzzy insuffisant ({best_score}), utilisation de l'IA...")
            print(f"   Analyse de {len(candidates)} candidats en une requ√™te...")
            self.total_ai_requests += 1
            
            selected_idx, matched_name, confidence_score = ai_compare_hospital_names_batch(
                establishment_name_clean, candidates, establishment_type
            )
            
            if selected_idx == -1:  # Aucune correspondance
                print(f"ü§ñ IA: Aucune correspondance trouv√©e")
                return None, "AUCUNE CORRESPONDANCE", 0, None
            
            print(f"üéØ Match IA s√©lectionn√© (confiance: {confidence_score}%):")
            print(f"   {establishment_name_clean} -> {matched_name}")
            return candidates[selected_idx][1], matched_name, confidence_score, "COLB_NOM_SC"
    
    def _fuzzy_match(self, establishment_name_clean, candidates):
        """
        Effectue un matching fuzzy et retourne le meilleur score
        """
        best_match_idx = -1
        best_score = 0
        
        for i, (candidate_name, finess) in enumerate(candidates):
            score = fuzz._token_sort(establishment_name_clean, candidate_name)
            if score > best_score:
                best_score = score
                best_match_idx = i
        
        return best_match_idx, best_score
    
    def _print_final_statistics(self):
        """
        Affiche les statistiques finales
        """
        print(f"\nüéâ === R√âSULTATS FINAUX ===")
        print(f"üìä Total d'√©tablissements dans le fichier: {len(self.df_lp)}")
        print(f"üîÑ √âtablissements trait√©s dans cette session: {self.processed_hospitals}")
        print(f"ü§ñ Total de requ√™tes IA utilis√©es: {self.total_ai_requests}")
        
        matches_found = self.df_lp[COLA_FINESS].notna().sum()
        no_matches = self.df_lp[COLA_FINESS].isna().sum()
        success_rate = matches_found / len(self.df_lp) * 100
        
        print(f"‚úÖ Matches trouv√©s: {matches_found}/{len(self.df_lp)} ({success_rate:.1f}%)")
        print(f"‚ùå Aucun match: {no_matches}")
        
        if no_matches == 0:
            print("üéä Traitement 100% termin√© !")
        else:
            print(f"‚è≥ {no_matches} √©tablissements restent √† traiter")
    
    def save_results(self):
        """
        Sauvegarde les r√©sultats dans un fichier Excel
        """
        print(f"\nüíæ Enregistrement des r√©sultats...")
        
        try:
            import os
            if not os.path.exists(os.path.dirname(OUTPUT_PATH)):
                os.makedirs(os.path.dirname(OUTPUT_PATH))
                
            self.df_lp.to_excel(OUTPUT_PATH, index=False)
            print(f"‚úÖ R√©sultats enregistr√©s dans {OUTPUT_PATH}")
        except Exception as e:
            print(f"‚ùå Erreur lors de l'enregistrement: {e}")
            raise
    
    def _save_intermediate_results(self, processed_count):
        """
        Sauvegarde interm√©diaire tous les SAVE_INTERVAL h√¥pitaux
        """
        try:
            total_matches = self.df_lp[COLA_FINESS].notna().sum()
            print(f"\nüíæ Sauvegarde interm√©diaire apr√®s {processed_count} nouveaux h√¥pitaux trait√©s...")
            print(f"üìä Total de matches dans le fichier: {total_matches}")
            
            # Sauvegarder dans le fichier principal (√©crase √† chaque fois)
            if not os.path.exists(os.path.dirname(OUTPUT_PATH)):
                os.makedirs(os.path.dirname(OUTPUT_PATH))
            
            self.df_lp.to_excel(OUTPUT_PATH, index=False)
            print(f"‚úÖ Sauvegarde r√©ussie: {OUTPUT_PATH}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de la sauvegarde interm√©diaire: {e}")
            # Continue le traitement m√™me en cas d'erreur de sauvegarde
